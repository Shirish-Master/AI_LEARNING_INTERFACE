# ğŸ“š AI Learning Interface

An interactive desktop application that combines computer vision, speech synthesis, and AI-powered conversations to provide a dynamic learning experience. It uses Google Vision API for object and text recognition, OpenAI for intelligent question generation, and pyttsx3 for speech output â€” all wrapped in a modern GUI with `CustomTkinter`.

---

## ğŸ§  Features

- ğŸ“· **Live Camera Feed** â€“ Detect objects and text in real time using your webcam.
- ğŸ§¾ **Google Vision API Integration** â€“ Automatically extracts objects and OCR data from images.
- ğŸ¤– **AI-Powered Q&A** â€“ Uses OpenAI's GPT to generate follow-up questions and respond to user queries.
- ğŸ—£ï¸ **Speech Synthesis** â€“ Reads AI responses aloud using `pyttsx3`.
- ğŸ¯ **Learning Progress Bar** â€“ Tracks user interaction with dynamic questions.
- ğŸ–±ï¸ **Dynamic Button Generation** â€“ Creates question buttons that adapt to detected content.
- ğŸŒ™ **Dark Mode UI** â€“ Built with `CustomTkinter` for a modern, themed interface.

---

## ğŸ› ï¸ Technologies Used

- `Python`
- `OpenCV`
- `Google Cloud Vision`
- `OpenAI API`
- `pyttsx3`
- `CustomTkinter`
- `Pillow`

---

## ğŸ“¦ Installation

### 1. Clone the repository

```
git clone https://github.com/yourusername/ai-learning-interface.git
cd ai-learning-interface
```

### 2. Set up a virtual environment (optional but recommended)

```
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install dependencies

```
pip install -r requirements.txt
```

### 4. Configure API keys

-Place your Google Cloud Vision API JSON key file as vision_api_key.json in the project root.

-Replace "OPENAPIKEY" in the code with your actual OpenAI API key or set it as an environment variable.

## ğŸš€ Usage

Run the application with:

```
python main.py
```

## Usage

- Click **Start Camera** to begin live object and text detection.
- Detected objects and texts appear as clickable buttons on the left.
- Clicking these buttons generates follow-up questions.
- Type your own questions or select generated ones to interact with the AI.
- Use **Send** to submit queries and **Stop** to halt speech output.
- The progress bar tracks your learning progress based on question interactions.

## ğŸ“ Notes

- Requires a working webcam for live detection.
- Ensure you have an active internet connection for OpenAI and Google Vision API calls.
- The speech engine uses your systemâ€™s default voice.

